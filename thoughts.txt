command line things that I have run

Tests to conduct:
Run CIFAR10 (DONE)
mkdir cifar10_with_bars
python -u main_PrAC_imp.py --data data/cifar10 --dataset cifar10 --arch res20s --split_file npy_files/cifar10-train-val.npy --batch_size 128 --lr 0.1 --pruning_times 16 --eb_eps 0.08 --prune_type rewind_lt --rewind_epoch 2 --threshold 0 --save_dir cifar10_with_bars > cifar10_with_bars/output.log

Run CIFAR100 (DONE)
mkdir cifar100_with_bars
python -u main_PrAC_imp.py --data data/cifar100 --dataset cifar100 --arch res20s --split_file npy_files/cifar100-train-val.npy --batch_size 128 --lr 0.1 --pruning_times 16 --eb_eps 0.08 --prune_type rewind_lt --rewind_epoch 2 --threshold 0 --save_dir cifar100_with_bars > cifar100_with_bars/output.log

Run MNIST at 16 pruning stages and observe bar graph output (FIX)
mkdir mnist_with_bars
python -u main_PrAC_imp.py --data data/mnist --dataset mnist --arch res20s --split_file npy_files/mnist-train-val.npy --batch_size 128 --lr 0.1 --pruning_times 16 --eb_eps 0.08 --prune_type rewind_lt --rewind_epoch 2 --threshold 0 --save_dir mnist_with_bars > mnist_with_bars/output.log

Run script - bar graph output script that combines the bar graphs at the final pruning state of all 3 datasets and outputs it as a bar graph
python utils/compare_bars.py

## MODIFY CODE TO REMOVE ONE OF THE PRUNING METHODS OR ADD COMMAND LINE ARGUMENT

Run CIFAR10 with only one of the pruning methods described and observe accuracy output
mkdir cifar10_hard_to_memorize
python -u main_PrAC_imp.py --data data/cifar10 --dataset cifar10 --arch res20s --split_file npy_files/cifar10-train-val.npy --batch_size 128 --lr 0.1 --pruning_times 16 --eb_eps 0.08 --prune_type rewind_lt --rewind_epoch 2 --threshold 0 --save_dir cifar10_hard_to_memorize > cifar10_hard_to_memorize/output.log

Run CIFAR10 with other pruning method described and observe accuracy output
mkdir cifar10_easy_to_forget
python -u main_PrAC_imp.py --core_set_method easy_to_forget --data data/cifar10 --dataset cifar10 --arch res20s --split_file npy_files/cifar10-train-val.npy --batch_size 128 --lr 0.1 --pruning_times 16 --eb_eps 0.08 --prune_type rewind_lt --rewind_epoch 2 --threshold 0 --save_dir cifar10_easy_to_forget > cifar10_easy_to_forget/output.log

Run CIFAR100 with only one of the pruning methods described and observe accuracy output
Run CIFAR100 with other pruning method described and observe accuracy output

Run MNIST with only one of the pruning methods described and observe accuracy output
Run MNIST with other pruning method described and observe accuracy output

Print out a couple samples from each type of data for each dataset

Hypothesize that the hard to memorize samples are the most important and don't need to include the other ones.

Idea for experiment: find the classification that has the greatest error rate in testing and include more of those in the PrAC set.